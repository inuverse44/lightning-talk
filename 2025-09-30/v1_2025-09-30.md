---
marp: true
theme: default
size: 16:9
paginate: true
math: mathjax
header: '待ち行列理論で考えるGKEの最適なポッド数'
footer: 'Inuverse/**エンジニアたちのゆるっと数学勉強会 #10**@2025-09-30, 福岡市天神エンジニアカフェ'

style: |
  /* 三重引用を脚注の記号に転用 */
  /* 下記はdefaultテーマ用。他のテーマで利用するときはbottomとleftを調節してください。 */
  /* スライド全体で利用するため、無名のstyleタグを利用しています。 */
  blockquote > blockquote > blockquote {
    font-size: 50%;
    font-weight: 400;
    padding: 0;
    margin: 0;
    border: 0;
    border-top: 0.1em dashed #555;
    position: absolute;
    bottom: 70px;
    left: 70px;
  }
---

<!-- _class: lead -->

# 待ち行列理論で考えるGKEの最適なポッド数

## Inuverse

**エンジニアたちのゆるっと数学勉強会 #10**
@2025-09-30, 福岡市天神エンジニアカフェ 


---

## 目次

0. 自己紹介
1. 動機と示したいこと
2. 準備
    - GKEとは
    - 待ち行列とは
    - Poisson分布と指数分布
3. 解析
4. 結果
5. 結論と展望

---

## 自己紹介

![bg right:35% 100% fit](assets/inuverse.jpg) 
![bg right:35% 120% fit](assets/qr_inuverse.png) 

- Inuverse（いぬばーす）（=こだま）
  - @mochi_dog_phys
- 2年目
- とある小売企業Tの基幹システムでo11y計装, API開発, 負荷検証
- 物理学、とくに宇宙が好き

---

## 動機と示したいこと
### 動機
- 負荷検証でGKEのポッドにAPIで大量のリクエスト
- Cloud LoggingやCloud Traceで負荷状況を観測
  - 負荷とポッドのリソースはどのような関係だろう。。。
$$ 
  \frac{d R(t)}{dt} 
  \sim  
  (C_{負荷} +  C_{処理能力})R(t)
$$

### 示したいこと
- 負荷と処理能力を軸にして、どれくらいのポッドの数であれば安全？
- SLOを満たすポッド数は？

>>> 1. $C_{負荷}, C_{処理能力}$を厳密に定義しているわけなく、当初の個人的な想像である。例えば負荷が$C_{負荷} = 0$のときを想定すると、明らかに上記の式は破綻する。


---

## 準備
<!-- メモ： 重要な本筋ではないざっと紹介だけする。負荷検証の文脈について、ポッドが水平スケールしてくれることを強調する。-->
GKEとは
> GKE は、Google が管理する Kubernetes オープンソース コンテナ オーケストレーション プラットフォームです。

[https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview?hl=ja](https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview?hl=ja)

Kubernatesとは
> Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. 

[https://kubernetes.io/docs/concepts/overview/](https://kubernetes.io/docs/concepts/overview/)

--- 

## 準備
### 待ち行列理論 (Queueing theory) とは

- 確率が時間発展し、混雑状況が時事刻々と変化する系を記述するための理論
  - 到着過程 (arrival process)
  - サービス過程 (service process)
- M/M/cモデル
  - 今回採用するモデル
  - 負荷が**ランダム**に到着し、処理の時間も**ランダム**で、それを実行してくれるサーバが$c$個存在する、という意味
  - 到着がランダム$\longrightarrow$ Poissn分布、処理時間がランダム $\longrightarrow$ 指数分布

>>> 1. [A. K. Erlang (1909)](https://www.medicine.mcgill.ca/epidemiology/hanley/statbook/Erlang1909.pdf)


---

## 準備
### Poisson分布と指数分布
<!-- うまく配置できないから、暫定的に表にする -->

<!-- 単位時間の平均リクエスト数を\lambdaとしたとき、単位時間に$k$個のリクエストが来る確率は？？-->

<!-- 単位時間あたりに$\mu$個の処理ができる確率は-->
<!-- 指数分布ってt=0のときどうなるの？-->
|ポアソン分布|指数分布|
|---|---|
|![w:500](https://storage.googleapis.com/zenn-user-upload/b13bb773ce1f-20250709.jpeg)| ![w:500](https://storage.googleapis.com/zenn-user-upload/2aeb1be1fd8b-20250709.jpeg) |


--- 

## 解析
- $P_n(t)$：待ち行列に$n$個のプロセスが残っている確率
- $\lambda$：平均リクエスト数（平均的な負荷を量）
- $\mu_n$：$n$個のプロセスが残っているときの、平均処理時間

$$
	\frac{\mathrm{d} P_n(t)}{\mathrm{d}t}
	= \lambda P_{n-1}(t)
	+ \mu_{n + 1} P_{n+1}(t)
	- (\lambda + \mu_n) P_n(t)
$$

>>> 1. 今回はAPIのリクエストで負荷をかけているという状況を考えているが、一般にこの限りではない。
>>> 2. [https://ia601403.us.archive.org/13/items/in.ernet.dli.2015.134547/2015.134547.Queueing-Systems-Volume-1-Theory.pdf](https://ia601403.us.archive.org/13/items/in.ernet.dli.2015.134547/2015.134547.Queueing-Systems-Volume-1-Theory.pdf)


---
## 解析
- ポッド数を調整するとして、最終的にポッド数は落ち着くはず $\longrightarrow \frac{{\rm d}P_n(t)}{{\rm d} t} = 0$
  - 負荷が高いままならHPAする$\longrightarrow \frac{{\rm d}P_n(t)}{{\rm d} t} \neq 0$

$$
	\underbrace{(\lambda + \mu_n) P_n(t)}_{\tiny{状態nから状態n-1 or n+1への流れ}}
	=
	\underbrace{\lambda P_{n-1}(t)}_{\tiny{状態n-1からnへの流れ}}
	+ \underbrace{\mu_{n + 1} P_{n+1}(t)}_{\tiny{状態n+1からnへの流れ}}
$$

- これが成り立つとき、詳細釣り合いの式
$$	
  \lambda P_{n-1} 
  = \mu_n P_n
$$

$\Longrightarrow$ある程度CPU使用が高い状態を維持しているとき、リクエストの早さと処理の速さが同じ、ということを表しています。

--- 
## 解析

$\mu_n = n \mu$とします：

### (i) $n < c$の場合

$$
	P_n 
	= \frac{1}{n!} \left( 
		\frac{\lambda}{\mu} 
	\right)^n P_0
$$

### (ii) $n > c$の場合

$$
	P_n 
	= \frac{1}{c!} \left( 
		\frac{\lambda}{\mu} 
	\right)^c \left( 
		\frac{\lambda}{c\mu} 
	\right)^{n-c} P_0
$$


--- 

## 解析
### $P_0$を求める
確率の規格化条件$\sum_{n = 0}^\infty P_n = 1$を使います。
前述の$P_n$を代入することで、最終的に

$$
	P_0 
	= 
	\left[ 
		\sum_{n=0}^{c-1} \frac{1}{n!} \left( 
			\frac{\lambda}{\mu} 
		\right)^n + \frac{1}{c!} \left( 
			\frac{\lambda}{\mu} 
		\right)^c 
		\frac{c\mu}{c\mu - \lambda} 
	\right]^{-1}
$$
と表されます。

>>> $\lambda < c\mu$は暗に仮定される。無限級数が計算できるためにはこれが必要であるし、そもそも実質的には、負荷が処理能力よりも大きい場合を許容しない。この不等式が必ず満たされる前提で話を進める。

--- 

## 解析
### 平均待ち行列長
- 平均待ち行列長$L_q$（系に残っているプロセスの期待値）は
$$
	L_q 
	= \sum_{n=c}^\infty (n - c) P_n\,.
$$

- 計算を進めると、
$$
	L_q
	=
	\underbrace{\frac{P_c}{1 - \rho}}_{\tiny{待ちが発生する確率}}
	\times 
	\underbrace{\frac{\rho}{1 - \rho}}_{\tiny{待ちのやばさ}}
$$
- $P_c$：$c$個のサーバがある系の待ち行列に$c$個のプロセスが残っている確率
- $\rho$：混み具合であり、$\rho = \lambda/(c\mu)$


---

## 解析
### 平均待ち時間
- *cf.* $\lambda$は単位時間あたりの平均的な負荷の量 $[T^{-1}]$

<!-- \lambdaが０のときはどうなるのか？ -->
$$
	W_q = \frac{L_q}{\lambda}
$$

- 平均待ち時間が$W_q$なので、待ち時間が$t$以下である確率は

$$
	P(W_q \leq t)
	= 1 - e^{- t/W_q}
$$


>>> $\lim_{\lambda \to 0 + 0}W_q = P_c$

---

## 解析
### 平均待ち時間
- 95%ile待ち時間を$W_{q, 95}$とします。待ち時間が$W_{q, 95}$を越さない確率が$0.95$なので

$$
	0.95 = 1 - \exp
	\left[
		- \frac{W_{q, 95}}{W_q}
	\right]
$$

- これを$W_{q, 95}$について解くと
$$
	W_{q, 95}
	= -W_q \underbrace{\log (0.05)}_{\simeq -2.995}
	\simeq 3 W_q
$$

- これは待ち時間なので、ユーザが体感する応答時間$W_{95}$は、
$$
	W_{95}
	\simeq 3W_{q} + \frac{1}{\mu}
$$


--- 
## 結果

- SLO: 95パーセンタイル時間が$200~{\rm msec}$以内に収める
- $\lambda$　リクエストが平均$\lambda = 100件 /{\rm sec}$
- $\mu$:　処理するにの$\mu = 20件/{\rm sec}$　

>>> このSLOの定義はよくありません。
--- 

## 結果

- $W_{q, 95} = W_{q, 95}(\lambda, \mu)$として、$\lambda, \mu$を動かして得たcontour plot

![w:800](https://storage.googleapis.com/zenn-user-upload/6ab263fd930e-20250711.png)

---

## 結論と展望

---

## Appendix
